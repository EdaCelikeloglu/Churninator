import plotly.express as px
import streamlit as st
import time
import numpy as np
import networkx as nx
import plotly.graph_objects as go
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import KNNImputer
from sklearn.neighbors import LocalOutlierFactor
from pywaffle import Waffle
from sklearn.preprocessing import OrdinalEncoder

st.set_page_config(page_title="Plotting Demo", page_icon="ðŸ“ˆ", layout="wide")

st.markdown("# Plotting Demo")
st.sidebar.header("Plotting Demo")
st.write(
    """This demo illustrates a combination of plotting and animation with
Streamlit. We're generating a bunch of random numbers in a loop for around
5 seconds. Enjoy!"""
)

# FonksiyonlarÄ±mÄ±z:
def grab_col_names(dataframe, cat_th=9, car_th=20):
    #cat_cols, cat_but_car
    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and
                   dataframe[col].dtypes != "O"]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and
                   dataframe[col].dtypes == "O"]
    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    #num_cols
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
    num_cols = [col for col in num_cols if col not in num_but_cat]

    print(f"Observations: {dataframe.shape[0]}")
    print(f"Variables: {dataframe.shape[1]}")
    print(f"cat_cols: {len(cat_cols)}")
    print(f"num_cols: {len(num_cols)}")
    print(f"cat_but_car: {len(cat_but_car)}")
    print(f"num_but_car: {len(num_but_cat)}")
    return cat_cols, num_cols, cat_but_car

def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):
    quartile1 = dataframe[col_name].quantile(q1)
    quartile3 = dataframe[col_name].quantile(q3)
    interquantile_range = quartile3 - quartile1
    up_limit = quartile3 + 1.5 * interquantile_range
    low_limit = quartile1 - 1.5 * interquantile_range
    return low_limit, up_limit

def check_outlier(dataframe, col_name):
    low_limit, up_limit = outlier_thresholds(dataframe, col_name)
    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):
        return True
    else:
        return False

def grab_outliers(dataframe, col_name, index=False):
    low, up = outlier_thresholds(dataframe, col_name)
    print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0])
    # if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:
    #     print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())
    # else:
    #     print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])

    if index:
        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index
        return outlier_index

def replace_with_thresholds(dataframe, variable):
    low_limit, up_limit = outlier_thresholds(dataframe, variable)
    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit
    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit

def cat_summary(dataframe, col_name, plot=False):
    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),
                        "Ratio": 100 * dataframe[col_name].value_counts() / len(dataframe)}))
    print("##########################################")
    if plot:
        sns.countplot(x=dataframe[col_name], data=dataframe)
        plt.show(block=True)

def num_summary(dataframe, numerical_col, plot=False):
    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]
    print(dataframe[numerical_col].describe(quantiles).T)

    if plot:
        dataframe[numerical_col].hist(bins=20)
        plt.xlabel(numerical_col)
        plt.title(numerical_col)
        plt.show(block=True)

def one_hot_encoder(dataframe, categorical_cols, drop_first=True):
    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first, dtype=int)
    return dataframe

def combine_categories(df, cat_col1, cat_col2, new_col_name):
    df[new_col_name] = df[cat_col1].astype(str) + '_' + df[cat_col2].astype(str)

df = pd.read_csv("BankChurners.csv")

df.drop([
    "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1",
    "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2"],
    inplace=True, axis=1)

# BaÄŸÄ±mlÄ± deÄŸiÅŸkenimizin ismini target yapalÄ±m ve 1, 0 atayalÄ±m:
df.rename(columns={"Attrition_Flag": "Target"}, inplace=True)
df["Target"] = df.apply(lambda x: 0 if (x["Target"] == "Existing Customer") else 1, axis=1)

# ID kolonunda duplicate bakÄ±p, sonra bu deÄŸiÅŸkeni silme
df["CLIENTNUM"].nunique()  # 10127 - yani duplicate yok id'de
df.drop("CLIENTNUM", axis=1, inplace=True)

cat_cols, num_cols, cat_but_car = grab_col_names(df)


# LOF
clf = LocalOutlierFactor(n_neighbors=20)
clf.fit_predict(df[num_cols])

df_scores = clf.negative_outlier_factor_

scores = pd.DataFrame(np.sort(df_scores))
scores.plot(stacked=True, xlim=[0, 100], style='.-')
plt.show()

th = np.sort(df_scores)[25]

df[df_scores < th].drop(axis=0, labels=df[df_scores < th].index)

cat_cols, num_cols, cat_but_car = grab_col_names(df)

# Missing values
cols_with_unknown = ['Income_Category', "Education_Level"]
for col in cols_with_unknown:
    df[col] = df[col].apply(lambda x: np.nan if x == 'Unknown' else x)

df["On_book_cat"] = np.where((df["Months_on_book"] < 12), "<1_year", np.where((df["Months_on_book"] < 24), "<2_years", np.where((df["Months_on_book"] < 36), "<3_years", np.where((df["Months_on_book"] < 48), "<4_years", "<5_years"))))
df['Total_Amt_Increased'] = np.where((df['Total_Amt_Chng_Q4_Q1'] > 0) & (df['Total_Amt_Chng_Q4_Q1'] < 1), 0, 1)
df["Has_debt"] = np.where((df["Credit_Limit"] > df["Avg_Open_To_Buy"]), 1, 0).astype(int)
df["Important_client_score"] = df["Total_Relationship_Count"] * (df["Months_on_book"] / 12)
df["Avg_Trans_Amt"] = df["Total_Trans_Amt"] / df['Total_Trans_Ct']

labels = ['Young', 'Middle_Aged', 'Senior']
bins = [25, 35, 55, 74]
df['Customer_Age_Category'] = pd.cut(df['Customer_Age'], bins=bins, labels=labels)

df["Days_Inactive_Last_Year"] = df["Months_Inactive_12_mon"] * 30
df["Days_Inactive_Last_Year"].value_counts()

# 0'larÄ± 1, 6'larÄ± 5 yapma:
df["Days_Inactive_Last_Year"].replace(0, 30, inplace=True)
df["Days_Inactive_Last_Year"].replace(180, 150, inplace=True)
# ÅŸu anda 5 sÄ±nÄ±fa ait oldular

# Recency score
# Ã§ok inactive (150) olanlarÄ±n score'u 1, az inactive olanlarÄ±n score'u (30) 5 olmalÄ±

df["RecencyScore"] = df["Days_Inactive_Last_Year"].apply(lambda x: 5 if x == 30 else
                                                        4 if x == 60 else
                                                        3 if x == 90 else
                                                        2 if x == 120 else
                                                        1 if x == 150 else x)

df["MonetaryScore"] = pd.qcut(df["Total_Trans_Amt"], 5, labels=[1, 2, 3, 4, 5])
df["FrequencyScore"] = pd.qcut(df["Total_Trans_Ct"], 5, labels=[1, 2, 3, 4, 5])
# # Total_Trans_Amt = Monetary
# # Total_Trans_Ct = Frequency
# # Days_Inactive_Last_Year = Recency


#buraya biÅŸeyler eklenecek rfm gÃ¼ncel hali




combine_categories(df, 'Customer_Age_Category', 'Marital_Status', 'Age_&_Marital')
combine_categories(df, 'Gender', 'Customer_Age_Category', 'Gender_&_Age')
combine_categories(df, "Card_Category", "Customer_Age_Category", "Card_&_Age")
combine_categories(df, "Gender", "FrequencyScore", "Gender_&_Frequency")
combine_categories(df, "Gender", "MonetaryScore", "Gender_&_Monetary")

df['Total_Amt_Increased'] = np.where((df['Total_Amt_Chng_Q4_Q1'] >= 0) & (df['Total_Amt_Chng_Q4_Q1'] < 1), 0, 1)
df['Total_Ct_Increased'] = np.where((df['Total_Ct_Chng_Q4_Q1'] >= 0) & (df['Total_Ct_Chng_Q4_Q1'] < 1), 0, 1)
df['Total_Ct_Chng_Q4_Q1'].describe().T
df['Total_Amt_Chng_Q4_Q1'].describe().T
df.loc[df['Total_Amt_Chng_Q4_Q1'] == 0]

# Total_Ct_Chng_Q4_Q1= Q4/Q1 olduÄŸuna gÃ¶re, bunun 0 olduÄŸu yerlerde Q4 = 0, yani recency'si 3 ay olur.
df.loc[df["Total_Ct_Chng_Q4_Q1"]==0]

# Ä°ÅŸlem sayÄ±sÄ± ve miktarÄ± pattern'leri:
# Ä°ÅŸlem sayÄ±sÄ± aynÄ± kalÄ±p, harcama miktarÄ± artanlar: (belki daha Ã§ok para kazanmaya baÅŸlamÄ±ÅŸlardÄ±r)(TODO kredi limiti ile incele)
df.loc[(df["Total_Ct_Chng_Q4_Q1"] == 1) & (df["Total_Amt_Chng_Q4_Q1"] > 1), "Ct_vs_Amt"] = "Same_ct_inc_amt"
# boÅŸ
df.loc[(df["Total_Ct_Chng_Q4_Q1"] == 1) & (df["Total_Amt_Chng_Q4_Q1"] == 1), "Ct_vs_Amt"] = "Same_ct_same_amt" # BOÅž
# Ä°ÅŸlem sayÄ±sÄ± aynÄ± kalÄ±p, harcama miktarÄ± azalanlar: (harcamalardan mÄ± kÄ±sÄ±yorlar? belki ihtiyaÃ§larÄ± olanlarÄ± almÄ±ÅŸlardÄ±r.) TODO May_Marry ile incele)
df.loc[(df["Total_Ct_Chng_Q4_Q1"] == 1) & (df["Total_Amt_Chng_Q4_Q1"] < 1), "Ct_vs_Amt"] = "Same_ct_dec_amt"
# iÅŸlem sayÄ±sÄ± da, miktarÄ± da artmÄ±ÅŸ (bizi sevindiren mÃ¼ÅŸteri <3 )
df.loc[(df["Total_Ct_Chng_Q4_Q1"] > 1) & (df["Total_Amt_Chng_Q4_Q1"] > 1), "Ct_vs_Amt"] = "Inc_ct_inc_amt"
# BOÅž Ä°ÅŸlem sayÄ±sÄ± artmasÄ±na raÄŸmen, harcama miktarÄ± aynÄ± kalanlar: (aylÄ±k ortalama harcama azalÄ±yor)
df.loc[(df["Total_Ct_Chng_Q4_Q1"] > 1) & (df["Total_Amt_Chng_Q4_Q1"] == 1), "Ct_vs_Amt"] = "Inc_ct_same_amt" # BOÅž
# Ä°ÅŸlem sayÄ±sÄ± artmÄ±ÅŸ ama miktar azalmÄ±ÅŸ. Yani daha sÄ±k, ama daha kÃ¼Ã§Ã¼k alÄ±ÅŸveriÅŸler yapÄ±yor. Bunlar dÃ¼ÅŸÃ¼k income grubuna aitse bankayÄ± mutlu edecek bir davranÄ±ÅŸ.
df.loc[(df["Total_Ct_Chng_Q4_Q1"] > 1) & (df["Total_Amt_Chng_Q4_Q1"] < 1), "Ct_vs_Amt"] = "Inc_ct_dec_amt"
#(df.loc[(df["Total_Ct_Chng_Q4_Q1"] > 1) & (df["Total_Amt_Chng_Q4_Q1"] < 1)]).groupby("Income_Category").count() # Evet, dÃ¼ÅŸÃ¼k income grubuna ait.
# Ä°ÅŸlem sayÄ±sÄ± azalmÄ±ÅŸ ama daha bÃ¼yÃ¼k miktarlarda harcama yapÄ±lÄ±yor:
df.loc[(df["Total_Ct_Chng_Q4_Q1"] < 1) & (df["Total_Amt_Chng_Q4_Q1"] > 1), "Ct_vs_Amt"] = "Dec_ct_inc_amt"
# Ä°ÅŸlem sayÄ±sÄ± azalmÄ±ÅŸ, toplam miktar aynÄ± kalmÄ±ÅŸ (yani ortalama harcama artmÄ±ÅŸ):
df.loc[(df["Total_Ct_Chng_Q4_Q1"] < 1) & (df["Total_Amt_Chng_Q4_Q1"] == 1), "Ct_vs_Amt"] = "Dec_ct_same_amt"
# Ä°ÅŸlem sayÄ±sÄ± azalmÄ±ÅŸ, miktar da azalmÄ±ÅŸ. Churn eder mi acaba?
df.loc[(df["Total_Ct_Chng_Q4_Q1"] < 1) & (df["Total_Amt_Chng_Q4_Q1"] < 1), "Ct_vs_Amt"] = "Dec_ct_dec_amt"
# (df.loc[(df["Total_Ct_Chng_Q4_Q1"] < 1) & (df["Total_Amt_Chng_Q4_Q1"] < 1)])["Target"].mean() # 0.17
df.head()

df.groupby("Ct_vs_Amt")["Target"].mean()
# Count arttÄ±kÃ§a churn etme olasÄ±lÄ±ÄŸÄ± azalÄ±yor.
df.groupby("Target")["Total_Trans_Ct"].mean()


df["Contacts_Count_12_mon"].describe().T
df.groupby("Contacts_Count_12_mon")["Target"].mean() # 6'larÄ±n hepsi churn. YÃ¼kseldikÃ§e churn olasÄ±lÄ±ÄŸÄ± artÄ±yor.
# TODO Number of contacts with the bank might indicate dissatisfaction or queries.
# 0   0.018
# 1   0.072
# 2   0.125
# 3   0.201
# 4   0.226
# 5   0.335
# 6   1.000


# Personalar
df["Affluent_criteria"] = (df['Income_Category'] == '$120K +').astype(int)
df["Budget_criteria"] = ((df['Income_Category'] == 'Less than $40K') & (df['Education_Level'].isin(['High School', 'College']))).astype(int)
df["Young_prof_criteria"] = ((df['Customer_Age'] <= 30) & (df['Education_Level'].isin(['College', 'Graduate']))).astype(int)
df["Family_criteria"] = ((df["Marital_Status"].isin(["Married", "Divorced", "Unknown"])) & (df['Dependent_count'] >= 3)).astype(int)
df["Credit_builder_criteria"] = (df['Credit_Limit'] < 2500).astype(int)  # This threshold is chosen to include individuals with credit limits in the lower percentiles of the distribution, which may indicate a need for credit-building strategies or entry-level credit products.
df["Digital_criteria"] = (df['Contacts_Count_12_mon'] == 0).astype(int)
df["High_net_worth_individual"] = ((df['Income_Category'] == '$120K +') & (df['Total_Trans_Amt'] > 5000)).astype(int)
df["Rewards_maximizer"] = ((df['Total_Trans_Amt'] > 10000) & (df['Total_Revolving_Bal'] == 0)).astype(int) # For the Rewards_maximizer column, the threshold for Total_Trans_Amt is also set at $10000. Since rewards maximizers are individuals who strategically maximize rewards and benefits from credit card usage, it's reasonable to expect that they engage in higher levels of spending. Therefore, the threshold of $10000 for Total_Trans_Amt appears appropriate for identifying rewards maximizers, considering that it captures individuals with relatively high spending habits.
df["May_marry"] = ((df["Age_&_Marital"] == "Young_Single") & (df['Dependent_count'] == 0)).astype(int)

# Total_Trans_Amt threshold'larÄ±nÄ± inceleyip Ã¼sttekiler iÃ§in ayarlama yapalÄ±m (Ã¼sttekiler ayarlama yapÄ±lmÄ±ÅŸ hali):
(df.loc[df['Total_Trans_Amt'] > 10000]).groupby("Income_Category")["Customer_Age"].mean()
(df.loc[df['Total_Trans_Amt'] > 10000]).groupby("Income_Category").count()
df['Total_Trans_Amt'].describe().T

df.head()

# TODO Ã¶neri: Total_dependent_count fazla olanlara ek kart Ã¶ner.

df.groupby("Income_Category")["Avg_Open_To_Buy"].mean()
df.groupby("Income_Category")["Credit_Limit"].mean()

df["Product_by_Year"] = df["Total_Relationship_Count"] / (df["Months_on_book"] / 12)
df["Product_by_Year"].describe().T
num_summary(df, "Product_by_Year", plot=True)

# MÃ¼ÅŸterinin yaÅŸÄ±nÄ± ve bankada geÃ§irdiÄŸi sÃ¼reyi birleÅŸtirerek uzun sÃ¼reli mÃ¼ÅŸteri olup olmadÄ±ÄŸÄ±nÄ± gÃ¶steren bir deÄŸiÅŸken oluÅŸturma
# Ay bilgilerini yÄ±la Ã§evirerek yeni bir sÃ¼tun oluÅŸturma
df['Year_on_book'] = df['Months_on_book'] // 12
df['Year_on_book'].value_counts()
# Year_on_book
# 3    5508
# 2    3115
# 4     817
# 1     687


df.head(20)
df.shape
cat_cols, num_cols, cat_but_car = grab_col_names(df)
df.info()


# Encoding:
dff = df.copy()

# Rare analyser:
def rare_analyser(dataframe, target, cat_cols):
    for col in cat_cols:
        print(col, ":", len(dataframe[col].value_counts()))
        print(pd.DataFrame({"COUNT": dataframe[col].value_counts(),
                            "RATIO": dataframe[col].value_counts() / len(dataframe),
                            "TARGET_MEAN": dataframe.groupby(col)[target].mean()}), end="\n\n\n")

rare_analyser(df, "Target", cat_cols)

# Rare encoding:
df["Card_Category"] = df["Card_Category"].apply(lambda x: "Gold_Platinum" if x == "Platinum" or x == "Gold" else x)
df["Months_Inactive_12_mon"] = df["Months_Inactive_12_mon"].apply(lambda x: 1 if x == 0 else x)
df["Ct_vs_Amt"] = df["Ct_vs_Amt"].apply(lambda x: "Dec_ct_inc_amt" if x == "Dec_ct_same_amt" else x)
df["Ct_vs_Amt"] = df["Ct_vs_Amt"].apply(lambda x: "Inc_ct_inc_amt" if x == "Same_ct_inc_amt" else x)
df["Contacts_Count_12_mon"] = df["Contacts_Count_12_mon"].apply(lambda x: 5 if x == 6 else x)
df["Card_&_Age"] = df["Card_&_Age"].apply(lambda x: "Rare" if df["Card_&_Age"].value_counts()[x] < 30 else x)
df["Card_&_Age"].value_counts()

cat_cols, num_cols, cat_but_car = grab_col_names(df)

""" KullanmadÄ±k ama mesela Card_&_Age'de ve Age_&_Marital'da 0.005 ratio'lu kategoriler var
def rare_encoder(dataframe, rare_perc):
    temp_df = dataframe.copy()

    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'
                    and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)] # any() Ã§Ã¼nkÃ¼ col'un value_counts/len'ini yani value'larÄ±nÄ±n yÃ¼zdelik ratio'larÄ±nÄ± alÄ±nca 0.01'den dÃ¼ÅŸÃ¼k herhangi biri (ANY) varsa, col'u al getir diyor.

    for var in rare_columns:
        tmp = temp_df[var].value_counts() / len(temp_df)     # bu ratio tablosunu, indeksi value (e.g. male/female), value'su ratio olacak ÅŸekilde pd.series (indeksli list) olarak kaydettim.
        rare_labels = tmp[tmp < rare_perc].index    # sonra bu listede deÄŸeri 0.01'den kÃ¼Ã§Ã¼k olanlarÄ±n indexini=label'Ä±nÄ± kaydettim.
        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])
        #temp_df["EMERGENCYSTATE_MODE"].isin(rare_labels) # output: tek bir sÃ¼tun iÃ§in her bir girdinin rare_labels'da olup olmamasÄ±na gÃ¶re T/F dÃ¶ndÃ¼rdÃ¼.

        # type(rare_columns) = pandas.series
        # tmp.dtype = float

    return temp_df


new_df = rare_encoder(df, 0.01)

rare_analyser(new_df, "TARGET", cat_cols)
"""


# Ordinal encoding:
def ordinal_encoder(dataframe, col):
    edu_cats = ['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate', np.nan]
    income_cats = ['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +', np.nan]
    customer_age_cat = ['Young', 'Middle_Aged', 'Senior']
    card_cat = ['Blue', 'Silver', 'Gold_Platinum']
    on_book_cat = ["<2_years", "<3_years", "<4_years", "<5_years"]

    if col == "Education_Level":
        col_cats = edu_cats
    if col == "Income_Category":
        col_cats = income_cats
    if col == "Customer_Age_Category":
        col_cats = customer_age_cat
    if col == "Card_Category":
        col_cats = card_cat
    if col == "On_book_cat":
        col_cats = on_book_cat

    ordinal_encoder = OrdinalEncoder(categories=[col_cats])  # burada direkt int alamÄ±yorum Ã§Ã¼nkÃ¼ NaN'lar mevcut.
    df[col] = ordinal_encoder.fit_transform(df[[col]])

    print(df[col].head(20))
    return df

for col in ["Education_Level", "Income_Category", "Customer_Age_Category", "Card_Category", "On_book_cat"]:
    df = ordinal_encoder(df, col)

df.columns
df.head()
cat_cols, num_cols, cat_but_car = grab_col_names(df)


# Nan doldurma:
imputer = KNNImputer(n_neighbors=10)
df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)

df["Education_Level"] = df["Education_Level"].round().astype(int)
df["Income_Category"] = df["Income_Category"].round().astype(int)








#33333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333
#tÃ¼m gÃ¶rselleÅŸtirme


# ÃœrÃ¼n sayÄ±sÄ± arttÄ±kÃ§a Churn olasÄ±lÄ±ÄŸÄ± azalÄ±yor
st.write("ÃœrÃ¼n sayÄ±sÄ± arttÄ±kÃ§a Churn olasÄ±lÄ±ÄŸÄ± azalÄ±yor.")
mean_target_by_relationship = df.groupby("Total_Relationship_Count")["Target"].mean().reset_index()
fig = px.bar(mean_target_by_relationship, x="Total_Relationship_Count", y="Target",
             labels={"Total_Relationship_Count": "Toplam ÃœrÃ¼n SayÄ±sÄ±", "Target": "Target"},
             title="Toplam ÃœrÃ¼n SayÄ±sÄ±na GÃ¶re Target", color_discrete_sequence=["blue"])
st.plotly_chart(fig)

# Yeni gelen mÃ¼ÅŸteriler risk mi?
st.write("Yeni gelen mÃ¼ÅŸteriler risk mi?")
mean_target_by_inactive_months = df.groupby("Months_Inactive_12_mon")["Target"].mean().reset_index()
fig = px.bar(mean_target_by_inactive_months, x="Months_Inactive_12_mon", y="Target",
             labels={"Months_Inactive_12_mon": "Ä°naktif Ay SayÄ±sÄ±", "Target": "Target"},
             title="Ä°naktif Ay SayÄ±sÄ±na GÃ¶re Target", color_discrete_sequence=px.colors.qualitative.Pastel)
st.plotly_chart(fig)

# Borcu Ã§ok olanlar gidemiyor
mean_utilization_by_target = df.groupby("Target")["Avg_Utilization_Ratio"].mean().reset_index()
mean_revolving_bal_by_target = df.groupby("Target")["Total_Revolving_Bal"].mean().reset_index()
fig_utilization = px.bar(mean_utilization_by_target, x="Target", y="Avg_Utilization_Ratio",
                         labels={"Target": "Hedef", "Avg_Utilization_Ratio": "BorÃ§/Kredi Limiti"},
                         title="Targete GÃ¶re BorÃ§/Kredi Limiti", color_discrete_sequence=px.colors.qualitative.Pastel)
fig_utilization.update_layout(height=400, width=400)
fig_revolving_bal = px.bar(mean_revolving_bal_by_target, x="Target", y="Total_Revolving_Bal",
                           labels={"Target": "Hedef", "Total_Revolving_Bal": "Ortalama Devir Bakiyesi"},
                           title="Hedefe GÃ¶re Ortalama Devir Bakiyesi", color_discrete_sequence=px.colors.qualitative.Pastel)
fig_revolving_bal.update_layout(height=400, width=400)
col1, col2 = st.columns(2)
with col1:
    st.plotly_chart(fig_utilization)
with col2:
    st.plotly_chart(fig_revolving_bal)


# Gelir kategorilerine gÃ¶re ortalama devir bakiyesi
fig = px.bar(df, x="Income_Category", y="Total_Revolving_Bal",
             labels={"Income_Category": "Gelir Kategorisi", "Total_Revolving_Bal": "Ortalama Devir Bakiyesi"},
             title="Gelir Kategorisine GÃ¶re Ortalama Devir Bakiyesi",
             color="Income_Category", color_discrete_sequence=px.colors.qualitative.Pastel)
# GrafiÄŸi gÃ¶rÃ¼ntÃ¼le
st.plotly_chart(fig, use_container_width=True)

# Target'e gÃ¶re Important_client_score'un grafiÄŸi:
mean_scores_by_target = df.groupby("Target")["Important_client_score"].mean().reset_index()
fig = px.bar(mean_scores_by_target, x="Target", y="Important_client_score",
             labels={"Target": "Hedef", "Important_client_score": "Ortalama Puan"},
             title="Targete GÃ¶re Important_client_score")
fig.update_layout(height=400, width=400)
st.plotly_chart(fig)

# mÃ¼ÅŸteri ile iletiÅŸim sayÄ±sÄ± ve target:
mean_churn_by_contact = df.groupby("Contacts_Count_12_mon")["Target"].mean().reset_index()
mean_churn_by_contact = mean_churn_by_contact.rename(columns={"Target": "Churn_Rate"})
fig = px.bar(mean_churn_by_contact, x="Contacts_Count_12_mon", y="Churn_Rate",
             labels={"Contacts_Count_12_mon": "Ä°letiÅŸim SayÄ±sÄ±", "Churn_Rate": "Ortalama Churn OranÄ±"},
             title="Ä°letiÅŸim SayÄ±sÄ±na GÃ¶re Ortalama Churn OranÄ±")
fig.update_layout(height=400, width=400)
st.plotly_chart(fig)



#Age_&_Marital   Gender_&_Age        Card_&_Age deÄŸiÅŸkenlerini target ile baktÄ±m:
fig_age_marital = px.histogram(df, x="Age_&_Marital", color="Target", barmode="group",
                                labels={"Age_&_Marital": "YaÅŸ ve Medeni Durum", "Target": "Churn Durumu"},
                                title="YaÅŸ ve Medeni Duruma GÃ¶re Churn Durumu")
fig_age_marital.update_layout(xaxis_title="YaÅŸ ve Medeni Durum", yaxis_title="SayÄ±")

fig_gender_age = px.histogram(df, x="Gender_&_Age", color="Target", barmode="group",
                               labels={"Gender_&_Age": "Cinsiyet ve YaÅŸ", "Target": "Churn Durumu"},
                               title="Cinsiyet ve YaÅŸa GÃ¶re Churn Durumu")
fig_gender_age.update_layout(xaxis_title="Cinsiyet ve YaÅŸ", yaxis_title="SayÄ±")

fig_card_age = px.histogram(df, x="Card_&_Age", color="Target", barmode="group",
                             labels={"Card_&_Age": "Kart ve YaÅŸ", "Target": "Churn Durumu"},
                             title="Kart ve YaÅŸa GÃ¶re Churn Durumu")
fig_card_age.update_layout(xaxis_title="Kart ve YaÅŸ", yaxis_title="SayÄ±")
st.plotly_chart(fig_age_marital)
st.plotly_chart(fig_gender_age)
st.plotly_chart(fig_card_age)


# burada Dec_ct_dec_amt kategorisi nedir? Ã‡ok fazla yoÄŸunluk var orda
#  Ct_vs_Amt ile Target:
fig = px.histogram(df, x="Ct_vs_Amt", color="Target", barmode="group",
                   title="Ct_vs_Amt DeÄŸiÅŸkeninin Target Ä°le Ä°liÅŸkisi",
                   labels={"Ct_vs_Amt": "Ct_vs_Amt", "Target": "Target OrtalamasÄ±"},
                   color_discrete_map={0: "lightblue", 1: "salmon"})

fig.update_layout(bargap=0.1)
st.plotly_chart(fig)

# bunun notunu almÄ±ÅŸÄ±m birlikte yorumlayalÄ±m.:
fig = px.scatter(df, x="Credit_Limit", y="Total_Revolving_Bal", color="Income_Category",
                 title="Kredi Limiti ve Devir Bakiyesi Ä°liÅŸkisi",
                 labels={"Credit_limit": "Kredi Limiti", "Total_revolving_Bal": "Devir Bakiyesi"},
                 color_discrete_sequence=px.colors.qualitative.Set2)
fig.update_layout(height=800, width=1200)
st.plotly_chart(fig)

#bÃ¼yÃ¼k Pasta
#'Education_Level' 'Income_Category' bunlarÄ± da koycam Nanlar sorun Ã§Ä±kardÄ±
fig = px.sunburst(df, path=['Target', 'Gender', 'Customer_Age_Category', 'Marital_Status'])
fig.update_layout(height=1000, width=1000)
# Streamlit ile gÃ¶sterme
st.plotly_chart(fig)
#bunun farklÄ± versiyonlarÄ±nÄ± deneyelim

#GÃ¼len YÃ¼zlerimiz
from pywaffle import Waffle
import matplotlib.pyplot as plt
import streamlit as st

count_1 = df['Target'].sum()
count_0 = len(df) - count_1
fig, ax = plt.subplots(figsize=(6, 4))
# Olumlu sembol
ax.text(0.5, 0.5, 'âœ”', color='green', fontsize=100, ha='center', va='center')
# Olumsuz sembol
ax.text(0.5, 0.5, 'âœ˜', color='red', fontsize=100, ha='center', va='center')
# Eksenleri gizle
ax.axis('off')
fig.show()
st.pyplot(fig)

count_1 = df['Target'].sum()
count_0 = len(df) - count_1
data = {'1 (Olumlu)': count_1, '0 (Olumsuz)': count_0}

fig = plt.figure(
    FigureClass=Waffle,
    rows=5,
    values=data,
    colors=("#008080", "#FF5733"),
    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},
    icons=('check', 'times'),
    icon_size=30,
    icon_legend=True,
    figsize=(10, 5)
)
fig.show()
st.pyplot(fig)



















# PCA ve waffle plot:
#bunu yapabilmek iÃ§in tÃ¼m veri scale edilmiÅŸ olmalÄ±
#o yÃ¼zden modele kadar herÅŸeyi Ã¼ste ekledim























progress_bar = st.sidebar.progress(0)
status_text = st.sidebar.empty()
last_rows = np.random.randn(1, 1)
chart = st.line_chart(last_rows)

for i in range(1, 101):
    new_rows = last_rows[-1, :] + np.random.randn(5, 1).cumsum(axis=0)
    status_text.text("%i%% Complete" % i)
    chart.add_rows(new_rows)
    progress_bar.progress(i)
    last_rows = new_rows
    time.sleep(0.05)

progress_bar.empty()

# Streamlit widgets automatically run the script from top to bottom. Since
# this button is not connected to any other logic, it just causes a plain
# rerun.
st.button("Re-run")